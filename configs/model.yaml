cv:
  scheme: rolling
  folds: 4
  min_train_year: 2000
  last_val_year: 2023
  gap_years: 0  # no gap between train/val

lightgbm:
  num_leaves: 63
  max_depth: 8
  learning_rate: 0.05
  n_estimators: 3000
  subsample: 0.8
  colsample_bytree: 0.8
  reg_lambda: 5.0
  reg_alpha: 0.0
  min_child_samples: 20
  objective: binary
  metric: binary_logloss
  boosting_type: gbdt
  verbosity: -1
  early_stopping_rounds: 100
  random_state: 42

calibration: platt  # or isotonic

# Hyperparameter search ranges (for tuning)
hyperparams:
  num_leaves: [31, 47, 63]
  max_depth: [6, 7, 8, 9]
  learning_rate: [0.03, 0.05, 0.08]
  colsample_bytree: [0.6, 0.7, 0.8, 0.9]
  subsample: [0.7, 0.8, 0.9]
  reg_lambda: [1, 3, 5, 10]

# Model artifacts
artifacts:
  model_path: "./models/model.pkl"
  calibrator_path: "./models/calibrator.pkl"
  feature_meta_path: "./models/feature_meta.json"
  model_card_path: "./models/model_card.md"

# Evaluation thresholds
thresholds:
  max_log_loss: 0.69
  max_brier: 0.24
  max_ece: 0.03